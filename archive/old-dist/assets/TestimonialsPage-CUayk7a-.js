import{j as e}from"./index-UkIvKgPy.js";const n=[{quote:"“We went from “it works on my machine” to deterministic runs with replayable configs. When a regression showed up, we traced it to a dataset version change in minutes instead of re-running the whole pipeline.”",name:"Nikhil Desai",title:"Staff Machine Learning Engineer",company:"Industrial automation platform (manufacturing)",context:"Standardized dataset → train → eval → export so handoffs stayed reproducible and regressions were attributable."},{quote:"“Our evaluation loop used to be a spreadsheet and a folder of checkpoints. With ML FORGE, every export is tied to the exact dataset snapshot and metrics—so we can audit what shipped without guesswork.”",name:"Sara Kim",title:"Computer Vision Lead",company:"Warehouse robotics team (autonomous picking)",context:"Cut evaluation/review cycles by ~40% by attaching evidence (configs, metrics, dataset snapshot) to every run and export."},{quote:"“Local execution was the dealbreaker. We can train and validate on restricted datasets without pushing anything to external services, while still maintaining a clean lineage trail for internal reviews.”",name:"Miguel Alvarez",title:"Principal ML Platform Engineer",company:"Healthcare imaging group (regulated environment)",context:"Kept sensitive data on-prem while improving audit readiness for model approvals and change control."},{quote:"“The biggest win wasn’t speed—it was eliminating ambiguity. Every run has a single source of truth: dataset version, config, artifacts, and metrics. When someone asks “why is this model better?”, we can answer with evidence.”",name:"Priya Nair",title:"Senior ML Engineer (Vision)",company:"Retail analytics org (loss prevention)",context:"Reduced time spent reconciling experiments by making comparisons evidence-based and reproducible."},{quote:"“We used to waste days reproducing training jobs from partial notes. Now we can re-run experiments reliably, and exports are consistent enough that deployment engineers stopped asking for “one more training run” to rebuild artifacts.”",name:"Ethan Brooks",title:"ML Infrastructure Engineer",company:"Edge AI systems integrator (embedded deployments)",context:"Reduced rework by packaging deployment-ready exports with the exact training evidence and configuration."},{quote:"“ML FORGE made our workflow reviewable. We’re not trusting a black box—every step is explicit, and the artifact trail is complete. That changed how confidently we promote models from experiments to releases.”",name:"Lina Haddad",title:"Engineering Manager, Applied AI",company:"Video analytics team (security)",context:"Introduced a repeatable promotion process with evidence gates, reducing rollback risk and “mystery model” incidents."}];function s({navigate:t}){return e.jsxs(e.Fragment,{children:[e.jsx("section",{className:"aboutHero tHero",children:e.jsxs("div",{className:"container aboutHero__inner tHero__inner",children:[e.jsx("p",{className:"aboutHero__kicker",children:"Testimonials"}),e.jsx("h1",{className:"aboutHero__title",children:"Engineer stories from reproducible Vision AI workflows"}),e.jsx("p",{className:"aboutHero__subtitle",children:"Technical teams adopt ML FORGE for determinism, traceability, and local execution. These are representative outcomes from real-world workflow constraints."}),e.jsxs("div",{className:"aboutHero__cta tHero__cta",children:[e.jsx("a",{className:"button button--primary",href:"/download",onClick:a=>{a.preventDefault(),t("/download")},children:"Download ML FORGE"}),e.jsx("a",{className:"button button--outline",href:"/workflow-automation",onClick:a=>{a.preventDefault(),t("/workflow-automation")},children:"See the workflow"})]})]})}),e.jsx("div",{className:"tBarcode","aria-hidden":"true",children:e.jsx("div",{className:"tBarcode__track"})}),e.jsx("section",{className:"aboutSection tSection",children:e.jsxs("div",{className:"container",children:[e.jsxs("div",{className:"sectionHeader tSectionHeader",children:[e.jsx("h2",{className:"sectionHeader__title",children:"What engineers actually value"}),e.jsx("p",{className:"sectionHeader__subtitle",children:"Reproducibility, auditability, and fewer unknowns in production."})]}),e.jsx("div",{className:"tGrid",role:"list",children:n.map(a=>e.jsxs("article",{className:"tCard",role:"listitem",children:[e.jsx("div",{className:"tCard__quote",children:a.quote}),e.jsxs("div",{className:"tCard__meta",children:[e.jsx("div",{className:"tCard__name",children:a.name}),e.jsx("div",{className:"tCard__title",children:a.title}),e.jsx("div",{className:"tCard__company",children:a.company})]}),e.jsx("div",{className:"tCard__context",children:a.context})]},`${a.name}-${a.title}`))})]})}),e.jsx("section",{className:"ctaBand",children:e.jsxs("div",{className:"container ctaBand__inner",children:[e.jsxs("div",{className:"ctaBand__copy",children:[e.jsx("h2",{className:"ctaBand__title",children:"Make reproducibility a default"}),e.jsx("p",{className:"ctaBand__subtitle",children:"Run locally. Keep evidence. Ship exports that can be traced back to their inputs."})]}),e.jsxs("div",{className:"ctaBand__actions",children:[e.jsx("a",{className:"button button--primary",href:"/download",onClick:a=>{a.preventDefault(),t("/download")},children:"Get the desktop app"}),e.jsx("a",{className:"button button--outline",href:"/guarantees",onClick:a=>{a.preventDefault(),t("/guarantees")},children:"Guarantees & boundaries"})]})]})})]})}export{s as default,n as testimonials};
